{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Digits 0 to 4 of MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to build and train a deep feed forward neural network to classify the \n",
    "first five digits, 0 to 4, of the MNIST dataset. \n",
    "\n",
    "Training is done using the low-level API of the **Tensorflow** framework. Steps involved include:\n",
    "* Download and preprocess MNIST dataset\n",
    "* Build DNN and train on dataset\n",
    "* Evaluate test accuracy of model and make some predictions\n",
    "* Tweak model to see if we achieve better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download and preprocess MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACRCAYAAADTnUPWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa467d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/tmp/data/')\n",
    "\n",
    "valid_size = 5000\n",
    "\n",
    "#extract digits 0 to 4 of training dataset\n",
    "train_index_0_4 = np.nonzero(mnist.train.labels <= 4)[0]\n",
    "mnist_train_images_0_4 = mnist.train.images[train_index_0_4]\n",
    "mnist_train_labels_0_4 = mnist.train.labels[train_index_0_4]\n",
    "\n",
    "#extract digits 0 to 4 of validation dataset\n",
    "valid_index_0_4 = np.nonzero(mnist.validation.labels <= 4)[0]\n",
    "mnist_valid_images_0_4 = mnist.validation.images[valid_index_0_4]\n",
    "mnist_valid_labels_0_4 = mnist.validation.labels[valid_index_0_4]\n",
    "\n",
    "#extract digits 0 to 4 of test dataset\n",
    "test_index_0_4 = np.nonzero(mnist.test.labels <= 4)[0]\n",
    "mnist_test_images_0_4 = mnist.test.images[test_index_0_4]\n",
    "mnist_test_labels_0_4 = mnist.test.labels[test_index_0_4]\n",
    "\n",
    "#display a sample of training, validation and test images\n",
    "plt.subplot(131)\n",
    "plt.imshow(mnist_train_images_0_4[10].reshape(28,28))\n",
    "plt.title('Training sample')\n",
    "plt.subplot(132)\n",
    "plt.imshow(mnist_valid_images_0_4[999].reshape(28,28))\n",
    "plt.title('Validation sample')\n",
    "plt.subplot(133)\n",
    "plt.imshow(mnist_test_images_0_4[1060].reshape(28,28))\n",
    "plt.title('Test sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and train DNN\n",
    "DNN to train consists of 5 hidden layers of 100 units each and an output layer of 5 units, one for each digit. Model is built and trained using low-level Tensorflow API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build phase of model\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 # each image of MNIST is 28 by 28 pixels\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    #use He initialization for weight initialization and Elu for activation function\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,activation=tf.nn.elu,units=units)\n",
    "    \n",
    "    hidden1 = my_hidden_layer(X,name='hidden1')\n",
    "    hidden2 = my_hidden_layer(hidden1,name='hidden2')\n",
    "    hidden3 = my_hidden_layer(hidden2,name='hidden3')\n",
    "    hidden4 = my_hidden_layer(hidden3,name='hidden4')\n",
    "    hidden5 = my_hidden_layer(hidden4,name='hidden5')\n",
    "    logits = tf.layers.dense(hidden5,n_outputs,name='logits')\n",
    "    \n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    #output layer uses softmax activation function\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    #optimizer is Adam optimizer with a learning rate of 0.001 \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op')\n",
    "    \n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    #operation to evaluate accuracy of model\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "\n",
    "#operation to initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#used to save the model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#path to where tensorboard log is saved\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tensorboard\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "#save graph and  stats used on the tensorboard\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Training Accuracy: 0.982143 Validation Accuracy: 0.982017\n",
      "1000 Training Accuracy: 1.0 Validation Accuracy: 0.982799\n",
      "1500 Training Accuracy: 1.0 Validation Accuracy: 0.979281\n",
      "2000 Training Accuracy: 1.0 Validation Accuracy: 0.989445\n",
      "2500 Training Accuracy: 1.0 Validation Accuracy: 0.987881\n",
      "3000 Training Accuracy: 1.0 Validation Accuracy: 0.9914\n",
      "3500 Training Accuracy: 1.0 Validation Accuracy: 0.988663\n",
      "4000 Training Accuracy: 1.0 Validation Accuracy: 0.990618\n",
      "4500 Training Accuracy: 0.964286 Validation Accuracy: 0.988272\n",
      "5000 Training Accuracy: 1.0 Validation Accuracy: 0.993354\n",
      "5500 Training Accuracy: 1.0 Validation Accuracy: 0.990227\n",
      "6000 Training Accuracy: 1.0 Validation Accuracy: 0.9914\n",
      "6500 Training Accuracy: 1.0 Validation Accuracy: 0.992963\n",
      "7000 Training Accuracy: 1.0 Validation Accuracy: 0.985927\n",
      "7500 Training Accuracy: 1.0 Validation Accuracy: 0.98749\n",
      "8000 Training Accuracy: 1.0 Validation Accuracy: 0.991009\n",
      "8500 Training Accuracy: 1.0 Validation Accuracy: 0.989445\n",
      "9000 Training Accuracy: 1.0 Validation Accuracy: 0.991009\n",
      "9500 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n",
      "10000 Training Accuracy: 1.0 Validation Accuracy: 0.987099\n",
      "10500 Training Accuracy: 1.0 Validation Accuracy: 0.99179\n",
      "11000 Training Accuracy: 1.0 Validation Accuracy: 0.99179\n",
      "11500 Training Accuracy: 1.0 Validation Accuracy: 0.99179\n",
      "12000 Training Accuracy: 1.0 Validation Accuracy: 0.994527\n",
      "12500 Training Accuracy: 1.0 Validation Accuracy: 0.990618\n",
      "13000 Training Accuracy: 1.0 Validation Accuracy: 0.9914\n",
      "13500 Training Accuracy: 1.0 Validation Accuracy: 0.9914\n",
      "14000 Training Accuracy: 1.0 Validation Accuracy: 0.988272\n",
      "14500 Training Accuracy: 1.0 Validation Accuracy: 0.992963\n",
      "15000 Training Accuracy: 1.0 Validation Accuracy: 0.989054\n",
      "15500 Training Accuracy: 1.0 Validation Accuracy: 0.994527\n",
      "16000 Training Accuracy: 1.0 Validation Accuracy: 0.992963\n",
      "16500 Training Accuracy: 1.0 Validation Accuracy: 0.995309\n",
      "17000 Training Accuracy: 1.0 Validation Accuracy: 0.989054\n",
      "17500 Training Accuracy: 1.0 Validation Accuracy: 0.994527\n",
      "18000 Training Accuracy: 1.0 Validation Accuracy: 0.993354\n",
      "18500 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n",
      "19000 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n",
      "19500 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n",
      "20000 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n",
      "20500 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n",
      "21000 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n",
      "21500 Training Accuracy: 1.0 Validation Accuracy: 0.993745\n"
     ]
    }
   ],
   "source": [
    "# Training phase of model\n",
    "\n",
    "# stop training if validation accuracy does not improve in 10 epochs\n",
    "# using early stopping to minimize overfitting\n",
    "max_epoch_without_valid_improve = 10 \n",
    "\n",
    "batch_size = 500\n",
    "global_step_count = 0 \n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() #initialize variables\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        #generate random mini-batches to use for training in current epoch\n",
    "        shuffle_idx = np.random.permutation(mnist_train_labels_0_4.shape[0])\n",
    "        x_batches = np.array_split(mnist_train_images_0_4[shuffle_idx],batch_size)\n",
    "        y_batches = np.array_split(mnist_train_labels_0_4[shuffle_idx],batch_size)\n",
    "        for x_batch,y_batch in zip(x_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={X:x_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        #evaluate training and validation accuracy\n",
    "        accu_train = accuracy.eval(feed_dict={X:x_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={X:mnist_valid_images_0_4,y:mnist_valid_labels_0_4})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        #save current validation and step count to tensorboard\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        #save model generated so far\n",
    "        saver.save(sess,'./saved_models/model_0_4.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    # save final model at end of trainiing\n",
    "    saver.save(sess,'./saved_models/model_0_4_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_models/model_0_4_final.ckpt\n",
      "Test Accuracy: 0.994941\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate accuracy of model on test dataset\n",
    "with tf.Session() as sess:\n",
    "    #restore saved model\n",
    "    saver.restore(sess,'./saved_models/model_0_4_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={X:mnist_test_images_0_4,y:mnist_test_labels_0_4})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_models/model_0_4_final.ckpt\n",
      "Prediction: [4 0 2 3 2 4]\n",
      "Target: [4 0 2 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "# Let's do some predictions on the test dataset using our model\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./saved_models/model_0_4_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={X:mnist_test_images_0_4[1989:1995]}),axis=1) \n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_0_4[1989:1995])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our trained model is working great! Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Batch Normalization\n",
    "Add batch normalization to model to see if we converge faster and better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build DNN with five hidden layers of 100 neurons each, with 5 output neurons to classify digits\n",
    "# 0 to 4 of MNIST using batch Normalization\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "is_training = tf.placeholder(tf.bool,shape=(),name=\"is_training\")\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,units=units)\n",
    "    my_batch_norm_layer = partial(tf.layers.batch_normalization,momentum=0.9,training=is_training)\n",
    "    \n",
    "    \n",
    "    hidden1 = my_hidden_layer(X,name='hidden1')\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1),name='bn1')\n",
    "    hidden2 = my_hidden_layer(bn1,name='hidden2')\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2),name='bn2')\n",
    "    hidden3 = my_hidden_layer(bn2,name='hidden3')\n",
    "    bn3 = tf.nn.elu(my_batch_norm_layer(hidden3),name='bn3')\n",
    "    hidden4 = my_hidden_layer(bn3,name='hidden4')\n",
    "    bn4 = tf.nn.elu(my_batch_norm_layer(hidden4),name='bn4')\n",
    "    hidden5 = my_hidden_layer(bn4,name='hidden5')\n",
    "    bn5 = tf.nn.elu(my_batch_norm_layer(hidden5),name='bn5')\n",
    "    logits_before_bn = tf.layers.dense(bn5,n_outputs,name='logits_before_bn')\n",
    "    logits = my_batch_norm_layer(logits_before_bn,name='logits')\n",
    "    \n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op')\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Training Accuracy: 0.978261 Validation Accuracy: 0.9838\n",
      "1000 Training Accuracy: 1.0 Validation Accuracy: 0.9848\n",
      "1500 Training Accuracy: 1.0 Validation Accuracy: 0.9858\n",
      "2000 Training Accuracy: 1.0 Validation Accuracy: 0.9876\n",
      "2500 Training Accuracy: 1.0 Validation Accuracy: 0.9884\n",
      "3000 Training Accuracy: 1.0 Validation Accuracy: 0.9878\n",
      "3500 Training Accuracy: 1.0 Validation Accuracy: 0.985\n",
      "4000 Training Accuracy: 1.0 Validation Accuracy: 0.9886\n",
      "4500 Training Accuracy: 1.0 Validation Accuracy: 0.9888\n",
      "5000 Training Accuracy: 1.0 Validation Accuracy: 0.9858\n",
      "5500 Training Accuracy: 1.0 Validation Accuracy: 0.9878\n",
      "6000 Training Accuracy: 1.0 Validation Accuracy: 0.9894\n",
      "6500 Training Accuracy: 1.0 Validation Accuracy: 0.9894\n",
      "7000 Training Accuracy: 1.0 Validation Accuracy: 0.9876\n",
      "7500 Training Accuracy: 1.0 Validation Accuracy: 0.986\n",
      "8000 Training Accuracy: 1.0 Validation Accuracy: 0.9884\n",
      "8500 Training Accuracy: 0.978261 Validation Accuracy: 0.9856\n"
     ]
    }
   ],
   "source": [
    "# Execution phase\n",
    "max_epoch_without_valid_improve = 5 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 500\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "x_batches = np.array_split(mnist_train_images_0_4,batch_size)\n",
    "y_batches = np.array_split(mnist_train_labels_0_4,batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        for x_batch,y_batch in zip(x_batches,y_batches):\n",
    "            sess.run([training_op,extra_update_ops],feed_dict={is_training:True,X:x_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={is_training:False,X:x_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={is_training:False,X:mnist_valid_images_0_4,y:mnist_valid_labels_0_4})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        saver.save(sess,'./model2.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    saver.save(sess,'./model2_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model2_final.ckpt\n",
      "Test Accuracy: 0.989492\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of batch normalization model on test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model2_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={is_training:False,X:mnist_test_images_0_4,y:mnist_test_labels_0_4})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model2_final.ckpt\n",
      "Prediction: [1 2 3 4 1]\n",
      "Target: [1 2 3 4 1]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data using batch normalization model\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model2_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={is_training:False,X:mnist_test_images_0_4[3000:3005]}),axis=1) \n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_0_4[3000:3005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's add dropout and see if we get better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build DNN with five hidden layers of 100 neurons each, with 5 output neurons to classify digits\n",
    "# 0 to 4 of MNIST using batch Normalization and dropout\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "dropout_rate = 0.5\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "is_training = tf.placeholder(tf.bool,shape=(),name=\"is_training\")\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,units=units)\n",
    "    my_batch_norm_layer = partial(tf.layers.batch_normalization,momentum=0.9,training=is_training)\n",
    "    \n",
    "    x_drop = tf.layers.dropout(X,rate=dropout_rate,training=is_training,name='x_drop')\n",
    "    \n",
    "    hidden1 = my_hidden_layer(x_drop,name='hidden1')\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1),name='bn1')\n",
    "    bn1_drop = tf.layers.dropout(bn1,rate=dropout_rate,training=is_training,name='bn1_drop')\n",
    "    \n",
    "    hidden2 = my_hidden_layer(bn1_drop,name='hidden2')\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2),name='bn2')\n",
    "    bn2_drop = tf.layers.dropout(bn2,rate=dropout_rate,training=is_training,name='bn2_drop')\n",
    "    \n",
    "    hidden3 = my_hidden_layer(bn2_drop,name='hidden3')\n",
    "    bn3 = tf.nn.elu(my_batch_norm_layer(hidden3),name='bn3')\n",
    "    bn3_drop = tf.layers.dropout(bn3,rate=dropout_rate,training=is_training,name='bn3_drop')\n",
    "    \n",
    "    hidden4 = my_hidden_layer(bn3_drop,name='hidden4')\n",
    "    bn4 = tf.nn.elu(my_batch_norm_layer(hidden4),name='bn4')\n",
    "    bn4_drop = tf.layers.dropout(bn4,rate=dropout_rate,training=is_training,name='bn4_drop') \n",
    "    \n",
    "    hidden5 = my_hidden_layer(bn4_drop,name='hidden5')\n",
    "    bn5 = tf.nn.elu(my_batch_norm_layer(hidden5),name='bn5')\n",
    "    bn5_drop = tf.layers.dropout(bn5,rate=dropout_rate,training=is_training,name='bn5_drop') \n",
    "    \n",
    "    logits_before_bn = tf.layers.dense(bn5_drop,n_outputs,name='logits_before_bn')\n",
    "    logits = my_batch_norm_layer(logits_before_bn,name='logits')\n",
    "    \n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op')\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Training Accuracy: 0.934783 Validation Accuracy: 0.9458\n",
      "1000 Training Accuracy: 0.934783 Validation Accuracy: 0.9528\n",
      "1500 Training Accuracy: 0.956522 Validation Accuracy: 0.9568\n",
      "2000 Training Accuracy: 0.956522 Validation Accuracy: 0.961\n",
      "2500 Training Accuracy: 0.956522 Validation Accuracy: 0.9618\n",
      "3000 Training Accuracy: 0.978261 Validation Accuracy: 0.9628\n",
      "3500 Training Accuracy: 0.978261 Validation Accuracy: 0.9648\n",
      "4000 Training Accuracy: 0.978261 Validation Accuracy: 0.965\n",
      "4500 Training Accuracy: 0.956522 Validation Accuracy: 0.9666\n",
      "5000 Training Accuracy: 0.978261 Validation Accuracy: 0.968\n",
      "5500 Training Accuracy: 0.978261 Validation Accuracy: 0.9686\n",
      "6000 Training Accuracy: 0.978261 Validation Accuracy: 0.9688\n",
      "6500 Training Accuracy: 0.978261 Validation Accuracy: 0.9706\n",
      "7000 Training Accuracy: 0.978261 Validation Accuracy: 0.9702\n",
      "7500 Training Accuracy: 0.978261 Validation Accuracy: 0.972\n",
      "8000 Training Accuracy: 0.978261 Validation Accuracy: 0.9716\n",
      "8500 Training Accuracy: 0.978261 Validation Accuracy: 0.974\n",
      "9000 Training Accuracy: 0.978261 Validation Accuracy: 0.9748\n",
      "9500 Training Accuracy: 0.978261 Validation Accuracy: 0.9758\n",
      "10000 Training Accuracy: 0.978261 Validation Accuracy: 0.9766\n",
      "10500 Training Accuracy: 0.978261 Validation Accuracy: 0.977\n",
      "11000 Training Accuracy: 0.978261 Validation Accuracy: 0.9768\n",
      "11500 Training Accuracy: 0.978261 Validation Accuracy: 0.9768\n",
      "12000 Training Accuracy: 1.0 Validation Accuracy: 0.9778\n",
      "12500 Training Accuracy: 0.978261 Validation Accuracy: 0.9788\n",
      "13000 Training Accuracy: 1.0 Validation Accuracy: 0.979\n",
      "13500 Training Accuracy: 1.0 Validation Accuracy: 0.978\n",
      "14000 Training Accuracy: 1.0 Validation Accuracy: 0.9786\n",
      "14500 Training Accuracy: 1.0 Validation Accuracy: 0.9786\n",
      "15000 Training Accuracy: 0.978261 Validation Accuracy: 0.979\n",
      "15500 Training Accuracy: 1.0 Validation Accuracy: 0.9794\n",
      "16000 Training Accuracy: 1.0 Validation Accuracy: 0.9794\n",
      "16500 Training Accuracy: 1.0 Validation Accuracy: 0.9788\n",
      "17000 Training Accuracy: 1.0 Validation Accuracy: 0.9804\n",
      "17500 Training Accuracy: 1.0 Validation Accuracy: 0.9798\n",
      "18000 Training Accuracy: 1.0 Validation Accuracy: 0.9818\n",
      "18500 Training Accuracy: 1.0 Validation Accuracy: 0.9798\n",
      "19000 Training Accuracy: 1.0 Validation Accuracy: 0.9806\n",
      "19500 Training Accuracy: 1.0 Validation Accuracy: 0.9798\n",
      "20000 Training Accuracy: 1.0 Validation Accuracy: 0.9814\n",
      "20500 Training Accuracy: 1.0 Validation Accuracy: 0.9828\n",
      "21000 Training Accuracy: 1.0 Validation Accuracy: 0.982\n",
      "21500 Training Accuracy: 1.0 Validation Accuracy: 0.9812\n",
      "22000 Training Accuracy: 1.0 Validation Accuracy: 0.9812\n",
      "22500 Training Accuracy: 1.0 Validation Accuracy: 0.9828\n",
      "23000 Training Accuracy: 1.0 Validation Accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# Execution phase\n",
    "max_epoch_without_valid_improve = 5 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 500\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "x_batches = np.array_split(mnist_train_images_0_4,batch_size)\n",
    "y_batches = np.array_split(mnist_train_labels_0_4,batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        for x_batch,y_batch in zip(x_batches,y_batches):\n",
    "            sess.run([training_op,extra_update_ops],feed_dict={is_training:True,X:x_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={is_training:False,X:x_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={is_training:False,X:mnist_valid_images_0_4,y:mnist_valid_labels_0_4})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        saver.save(sess,'./model3.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    saver.save(sess,'./model3_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model3_final.ckpt\n",
      "Test Accuracy: 0.989881\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of batch normalization and dropout model on test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model3_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={is_training:False,X:mnist_test_images_0_4,y:mnist_test_labels_0_4})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model3_final.ckpt\n",
      "Prediction: [1 2 3 4 1]\n",
      "Target: [1 2 3 4 1]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data using batch normalization and dropout model\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model3_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={is_training:False,X:mnist_test_images_0_4[3000:3005]}),axis=1) \n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_0_4[3000:3005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "Training a new DNN to classify digits 5 to 9 using pretained hidden layers of model that classifies digits 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess data for training. Using only 100 images per digit (5 to 9) for training\n",
    "# shift labels such that  5->0,6->1,7->2,8->3,9->4\n",
    "import numpy as np\n",
    "\n",
    "index_5 = np.random.permutation(np.nonzero(mnist.train.labels == 5)[0])[:100] #  get 100 images for 5\n",
    "index_6 = np.random.permutation(np.nonzero(mnist.train.labels == 6)[0])[:100] #  get 100 images for 6\n",
    "index_7 = np.random.permutation(np.nonzero(mnist.train.labels == 7)[0])[:100] #  get 100 images for 7\n",
    "index_8 = np.random.permutation(np.nonzero(mnist.train.labels == 8)[0])[:100] #  get 100 images for 8\n",
    "index_9 = np.random.permutation(np.nonzero(mnist.train.labels == 9)[0])[:100] #  get 100 images for 9\n",
    "train_index_5_9 = np.random.permutation(np.hstack((index_5,index_6,index_7,index_8,index_9)))\n",
    "\n",
    "#training set\n",
    "mnist_train_images_5_9 = mnist.train.images[train_index_5_9]\n",
    "mnist_train_labels_5_9 = mnist.train.labels[train_index_5_9] - 5\n",
    "\n",
    "#validation set\n",
    "valid_index_5_9 = np.random.permutation(np.nonzero(mnist.validation.labels >= 5)[0]) \n",
    "mnist_valid_images_5_9 = mnist.validation.images[valid_index_5_9]\n",
    "mnist_valid_labels_5_9 = mnist.validation.labels[valid_index_5_9] - 5\n",
    "\n",
    "#test set\n",
    "test_index_5_9 = np.random.permutation(np.nonzero(mnist.test.labels >= 5)[0]) \n",
    "mnist_test_images_5_9 = mnist.test.images[test_index_5_9]\n",
    "mnist_test_labels_5_9 = mnist.test.labels[test_index_5_9] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xedd5e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACFCAYAAABL2gNbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCzoRkSVY0ImILMGCTkRkif8D76g7Ajrm2OUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xeadf6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show some sample images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplot(131)\n",
    "plt.imshow(mnist_train_images_5_9[17].reshape(28,28))\n",
    "plt.subplot(132)\n",
    "plt.imshow(mnist_valid_images_5_9[1031].reshape(28,28))\n",
    "plt.subplot(133)\n",
    "plt.imshow(mnist_test_images_5_9[3999].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a new DNN to classify digits 5 to 9 using  all 5 pretained hidden layers of the previous batch normalization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a new DNN to classify digits 5 to 9 using pretained hidden layers of the previous batch normalization model\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,activation=tf.nn.elu,units=units)\n",
    "    \n",
    "    hidden1 = my_hidden_layer(X,name='hidden1')\n",
    "    hidden2 = my_hidden_layer(hidden1,name='hidden2')\n",
    "    hidden3 = my_hidden_layer(hidden2,name='hidden3')\n",
    "    hidden4 = my_hidden_layer(hidden3,name='hidden4')\n",
    "    hidden5 = my_hidden_layer(hidden4,name='hidden5')\n",
    "    logits = tf.layers.dense(hidden5,n_outputs,name='logits')\n",
    "    \n",
    "    #define variables to save and restore\n",
    "    reuse_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\"hidden[12345]\")\n",
    "    reuse_vars_dict = dict([(var.op.name,var) for var in reuse_vars])\n",
    "    #print(reuse_vars_dict)\n",
    "    original_saver = tf.train.Saver(reuse_vars_dict)\n",
    "    \n",
    "    #define variables to train\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='logits')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op',var_list=train_vars)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model1_final.ckpt\n",
      "50 Training Accuracy: 0.4 Validation Accuracy: 0.473792\n",
      "100 Training Accuracy: 0.5 Validation Accuracy: 0.603604\n",
      "150 Training Accuracy: 0.4 Validation Accuracy: 0.665438\n",
      "200 Training Accuracy: 0.7 Validation Accuracy: 0.701474\n",
      "250 Training Accuracy: 0.8 Validation Accuracy: 0.716626\n",
      "300 Training Accuracy: 0.8 Validation Accuracy: 0.744472\n",
      "350 Training Accuracy: 0.7 Validation Accuracy: 0.753071\n",
      "400 Training Accuracy: 0.8 Validation Accuracy: 0.768632\n",
      "450 Training Accuracy: 0.9 Validation Accuracy: 0.77846\n",
      "500 Training Accuracy: 0.8 Validation Accuracy: 0.785422\n",
      "550 Training Accuracy: 0.9 Validation Accuracy: 0.79484\n",
      "600 Training Accuracy: 1.0 Validation Accuracy: 0.798935\n",
      "650 Training Accuracy: 0.8 Validation Accuracy: 0.80344\n",
      "700 Training Accuracy: 0.8 Validation Accuracy: 0.802621\n",
      "750 Training Accuracy: 0.8 Validation Accuracy: 0.810401\n",
      "800 Training Accuracy: 1.0 Validation Accuracy: 0.818591\n",
      "850 Training Accuracy: 0.8 Validation Accuracy: 0.81941\n",
      "900 Training Accuracy: 0.9 Validation Accuracy: 0.820639\n",
      "950 Training Accuracy: 0.9 Validation Accuracy: 0.823915\n",
      "1000 Training Accuracy: 0.8 Validation Accuracy: 0.827191\n",
      "1050 Training Accuracy: 0.9 Validation Accuracy: 0.831286\n",
      "1100 Training Accuracy: 1.0 Validation Accuracy: 0.833743\n",
      "1150 Training Accuracy: 0.9 Validation Accuracy: 0.834971\n",
      "1200 Training Accuracy: 0.9 Validation Accuracy: 0.837838\n",
      "1250 Training Accuracy: 0.8 Validation Accuracy: 0.839885\n",
      "1300 Training Accuracy: 0.9 Validation Accuracy: 0.839476\n",
      "1350 Training Accuracy: 1.0 Validation Accuracy: 0.845618\n",
      "1400 Training Accuracy: 1.0 Validation Accuracy: 0.845618\n",
      "1450 Training Accuracy: 0.9 Validation Accuracy: 0.841933\n",
      "1500 Training Accuracy: 0.9 Validation Accuracy: 0.846437\n",
      "1550 Training Accuracy: 1.0 Validation Accuracy: 0.847256\n",
      "1600 Training Accuracy: 1.0 Validation Accuracy: 0.847256\n",
      "1650 Training Accuracy: 1.0 Validation Accuracy: 0.849713\n",
      "1700 Training Accuracy: 0.9 Validation Accuracy: 0.850532\n",
      "1750 Training Accuracy: 1.0 Validation Accuracy: 0.850942\n",
      "1800 Training Accuracy: 0.9 Validation Accuracy: 0.847666\n",
      "1850 Training Accuracy: 0.9 Validation Accuracy: 0.851761\n",
      "1900 Training Accuracy: 0.9 Validation Accuracy: 0.85217\n",
      "1950 Training Accuracy: 1.0 Validation Accuracy: 0.854627\n",
      "2000 Training Accuracy: 0.9 Validation Accuracy: 0.853399\n",
      "2050 Training Accuracy: 1.0 Validation Accuracy: 0.854627\n",
      "2100 Training Accuracy: 0.9 Validation Accuracy: 0.85217\n",
      "2150 Training Accuracy: 1.0 Validation Accuracy: 0.851761\n",
      "2200 Training Accuracy: 1.0 Validation Accuracy: 0.855037\n",
      "2250 Training Accuracy: 0.8 Validation Accuracy: 0.856675\n",
      "2300 Training Accuracy: 1.0 Validation Accuracy: 0.855037\n",
      "2350 Training Accuracy: 1.0 Validation Accuracy: 0.859541\n",
      "2400 Training Accuracy: 1.0 Validation Accuracy: 0.858722\n",
      "2450 Training Accuracy: 1.0 Validation Accuracy: 0.857494\n",
      "2500 Training Accuracy: 0.9 Validation Accuracy: 0.858313\n",
      "2550 Training Accuracy: 1.0 Validation Accuracy: 0.859541\n",
      "2600 Training Accuracy: 1.0 Validation Accuracy: 0.857084\n",
      "2650 Training Accuracy: 1.0 Validation Accuracy: 0.856675\n",
      "2700 Training Accuracy: 1.0 Validation Accuracy: 0.859132\n",
      "2750 Training Accuracy: 1.0 Validation Accuracy: 0.857903\n",
      "2800 Training Accuracy: 1.0 Validation Accuracy: 0.86077\n",
      "2850 Training Accuracy: 1.0 Validation Accuracy: 0.858313\n",
      "2900 Training Accuracy: 1.0 Validation Accuracy: 0.86077\n",
      "2950 Training Accuracy: 0.9 Validation Accuracy: 0.859541\n",
      "3000 Training Accuracy: 0.9 Validation Accuracy: 0.861179\n",
      "3050 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "3100 Training Accuracy: 1.0 Validation Accuracy: 0.859951\n",
      "3150 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "3200 Training Accuracy: 0.9 Validation Accuracy: 0.861998\n",
      "3250 Training Accuracy: 1.0 Validation Accuracy: 0.86077\n",
      "3300 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "3350 Training Accuracy: 1.0 Validation Accuracy: 0.862408\n",
      "3400 Training Accuracy: 1.0 Validation Accuracy: 0.862408\n",
      "3450 Training Accuracy: 1.0 Validation Accuracy: 0.861998\n",
      "3500 Training Accuracy: 1.0 Validation Accuracy: 0.86036\n",
      "3550 Training Accuracy: 1.0 Validation Accuracy: 0.861998\n",
      "3600 Training Accuracy: 1.0 Validation Accuracy: 0.857494\n",
      "3650 Training Accuracy: 1.0 Validation Accuracy: 0.861998\n",
      "3700 Training Accuracy: 1.0 Validation Accuracy: 0.861998\n",
      "3750 Training Accuracy: 1.0 Validation Accuracy: 0.862817\n",
      "3800 Training Accuracy: 1.0 Validation Accuracy: 0.863227\n",
      "3850 Training Accuracy: 1.0 Validation Accuracy: 0.864455\n",
      "3900 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "3950 Training Accuracy: 1.0 Validation Accuracy: 0.863227\n",
      "4000 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "4050 Training Accuracy: 1.0 Validation Accuracy: 0.864865\n",
      "4100 Training Accuracy: 1.0 Validation Accuracy: 0.863636\n",
      "4150 Training Accuracy: 1.0 Validation Accuracy: 0.861998\n",
      "4200 Training Accuracy: 0.9 Validation Accuracy: 0.861998\n",
      "4250 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "4300 Training Accuracy: 1.0 Validation Accuracy: 0.862408\n",
      "4350 Training Accuracy: 1.0 Validation Accuracy: 0.859951\n",
      "4400 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "4450 Training Accuracy: 1.0 Validation Accuracy: 0.861998\n",
      "4500 Training Accuracy: 1.0 Validation Accuracy: 0.861179\n",
      "4550 Training Accuracy: 1.0 Validation Accuracy: 0.86036\n",
      "4600 Training Accuracy: 1.0 Validation Accuracy: 0.86077\n",
      "4650 Training Accuracy: 1.0 Validation Accuracy: 0.86077\n",
      "4700 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "4750 Training Accuracy: 1.0 Validation Accuracy: 0.861998\n",
      "4800 Training Accuracy: 1.0 Validation Accuracy: 0.863227\n",
      "4850 Training Accuracy: 1.0 Validation Accuracy: 0.863227\n",
      "4900 Training Accuracy: 0.9 Validation Accuracy: 0.862408\n",
      "4950 Training Accuracy: 0.9 Validation Accuracy: 0.861589\n",
      "5000 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "5050 Training Accuracy: 1.0 Validation Accuracy: 0.861179\n"
     ]
    }
   ],
   "source": [
    "#execution phase\n",
    "max_epoch_without_valid_improve = 20 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 50\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    original_saver.restore(sess,'./model1_final.ckpt')\n",
    "    hidden5_outputs = sess.run(hidden5,feed_dict={X:mnist_train_images_5_9})\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        shuffled_idx = np.random.permutation(hidden5_outputs.shape[0])\n",
    "        hidden5_batches = np.array_split(hidden5_outputs[shuffled_idx],batch_size)\n",
    "        y_batches = np.array_split(mnist_train_labels_5_9[shuffled_idx],batch_size)\n",
    "        \n",
    "        for hidden5_batch,y_batch in zip(hidden5_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={hidden5:hidden5_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={hidden5:hidden5_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={X:mnist_valid_images_5_9,y:mnist_valid_labels_5_9})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        new_saver.save(sess,'./model4.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    saver.save(sess,'./model4_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model4_final.ckpt\n",
      "Test Accuracy: 0.860934\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of batch normalization and dropout model on test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model4_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={X:mnist_test_images_5_9,y:mnist_test_labels_5_9})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model4_final.ckpt\n",
      "Prediction: [6 9 7 9 6]\n",
      "Target: [6 9 7 9 6]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data using batch normalization and dropout model\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model4_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={X:mnist_test_images_5_9[2920:2925]}),axis=1) + 5\n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_5_9[2920:2925] + 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf36e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show images corresponding to predicted digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplot(151)\n",
    "plt.imshow(mnist_test_images_5_9[2920].reshape(28,28))\n",
    "plt.subplot(152)\n",
    "plt.imshow(mnist_test_images_5_9[2921].reshape(28,28))\n",
    "plt.subplot(153)\n",
    "plt.imshow(mnist_test_images_5_9[2922].reshape(28,28))\n",
    "plt.subplot(154)\n",
    "plt.imshow(mnist_test_images_5_9[2923].reshape(28,28))\n",
    "plt.subplot(155)\n",
    "plt.imshow(mnist_test_images_5_9[2924].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a new DNN to classify digits 5 to 9 using first 4 pretained hidden layers of the previous batch normalization model (model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,activation=tf.nn.elu,units=units)\n",
    "    \n",
    "    hidden1 = my_hidden_layer(X,name='hidden1')\n",
    "    hidden2 = my_hidden_layer(hidden1,name='hidden2')\n",
    "    hidden3 = my_hidden_layer(hidden2,name='hidden3')\n",
    "    hidden4 = my_hidden_layer(hidden3,name='hidden4')\n",
    "    hidden5 = my_hidden_layer(hidden4,name='hidden5')\n",
    "    logits = tf.layers.dense(hidden5,n_outputs,name='logits')\n",
    "    \n",
    "    #define variables to save and restore\n",
    "    reuse_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\"hidden[1234]\")\n",
    "    reuse_vars_dict = dict([(var.op.name,var) for var in reuse_vars])\n",
    "    #print(reuse_vars_dict)\n",
    "    original_saver = tf.train.Saver(reuse_vars_dict)\n",
    "    \n",
    "    #define variables to train\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='hidden[5]|logits')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op',var_list=train_vars)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model1_final.ckpt\n",
      "50 Training Accuracy: 0.8 Validation Accuracy: 0.75389\n",
      "100 Training Accuracy: 0.8 Validation Accuracy: 0.803849\n",
      "150 Training Accuracy: 0.9 Validation Accuracy: 0.820229\n",
      "200 Training Accuracy: 1.0 Validation Accuracy: 0.834152\n",
      "250 Training Accuracy: 0.9 Validation Accuracy: 0.846437\n",
      "300 Training Accuracy: 1.0 Validation Accuracy: 0.863227\n",
      "350 Training Accuracy: 1.0 Validation Accuracy: 0.864455\n",
      "400 Training Accuracy: 1.0 Validation Accuracy: 0.866912\n",
      "450 Training Accuracy: 1.0 Validation Accuracy: 0.871007\n",
      "500 Training Accuracy: 0.9 Validation Accuracy: 0.875512\n",
      "550 Training Accuracy: 1.0 Validation Accuracy: 0.864046\n",
      "600 Training Accuracy: 1.0 Validation Accuracy: 0.87674\n",
      "650 Training Accuracy: 1.0 Validation Accuracy: 0.872236\n",
      "700 Training Accuracy: 1.0 Validation Accuracy: 0.872645\n",
      "750 Training Accuracy: 1.0 Validation Accuracy: 0.868141\n",
      "800 Training Accuracy: 1.0 Validation Accuracy: 0.871417\n",
      "850 Training Accuracy: 1.0 Validation Accuracy: 0.875102\n",
      "900 Training Accuracy: 1.0 Validation Accuracy: 0.873055\n",
      "950 Training Accuracy: 1.0 Validation Accuracy: 0.87674\n",
      "1000 Training Accuracy: 1.0 Validation Accuracy: 0.878788\n",
      "1050 Training Accuracy: 1.0 Validation Accuracy: 0.879197\n",
      "1100 Training Accuracy: 1.0 Validation Accuracy: 0.882064\n",
      "1150 Training Accuracy: 1.0 Validation Accuracy: 0.881654\n",
      "1200 Training Accuracy: 1.0 Validation Accuracy: 0.87715\n",
      "1250 Training Accuracy: 1.0 Validation Accuracy: 0.880426\n",
      "1300 Training Accuracy: 1.0 Validation Accuracy: 0.881245\n",
      "1350 Training Accuracy: 1.0 Validation Accuracy: 0.881245\n",
      "1400 Training Accuracy: 1.0 Validation Accuracy: 0.880016\n",
      "1450 Training Accuracy: 1.0 Validation Accuracy: 0.877559\n",
      "1500 Training Accuracy: 1.0 Validation Accuracy: 0.880016\n",
      "1550 Training Accuracy: 1.0 Validation Accuracy: 0.881654\n",
      "1600 Training Accuracy: 1.0 Validation Accuracy: 0.881245\n",
      "1650 Training Accuracy: 1.0 Validation Accuracy: 0.884521\n",
      "1700 Training Accuracy: 1.0 Validation Accuracy: 0.88493\n",
      "1750 Training Accuracy: 1.0 Validation Accuracy: 0.884521\n",
      "1800 Training Accuracy: 1.0 Validation Accuracy: 0.882883\n",
      "1850 Training Accuracy: 1.0 Validation Accuracy: 0.882064\n",
      "1900 Training Accuracy: 1.0 Validation Accuracy: 0.888206\n",
      "1950 Training Accuracy: 1.0 Validation Accuracy: 0.88534\n",
      "2000 Training Accuracy: 1.0 Validation Accuracy: 0.884111\n",
      "2050 Training Accuracy: 1.0 Validation Accuracy: 0.88534\n",
      "2100 Training Accuracy: 1.0 Validation Accuracy: 0.885749\n",
      "2150 Training Accuracy: 1.0 Validation Accuracy: 0.885749\n",
      "2200 Training Accuracy: 1.0 Validation Accuracy: 0.887387\n",
      "2250 Training Accuracy: 1.0 Validation Accuracy: 0.88493\n",
      "2300 Training Accuracy: 1.0 Validation Accuracy: 0.887387\n",
      "2350 Training Accuracy: 1.0 Validation Accuracy: 0.886568\n",
      "2400 Training Accuracy: 1.0 Validation Accuracy: 0.888616\n",
      "2450 Training Accuracy: 1.0 Validation Accuracy: 0.887387\n",
      "2500 Training Accuracy: 1.0 Validation Accuracy: 0.886978\n",
      "2550 Training Accuracy: 1.0 Validation Accuracy: 0.886978\n",
      "2600 Training Accuracy: 1.0 Validation Accuracy: 0.887387\n",
      "2650 Training Accuracy: 1.0 Validation Accuracy: 0.885749\n",
      "2700 Training Accuracy: 1.0 Validation Accuracy: 0.887797\n",
      "2750 Training Accuracy: 1.0 Validation Accuracy: 0.886568\n",
      "2800 Training Accuracy: 1.0 Validation Accuracy: 0.886568\n",
      "2850 Training Accuracy: 1.0 Validation Accuracy: 0.887387\n",
      "2900 Training Accuracy: 1.0 Validation Accuracy: 0.885749\n",
      "2950 Training Accuracy: 1.0 Validation Accuracy: 0.88534\n",
      "3000 Training Accuracy: 1.0 Validation Accuracy: 0.886159\n",
      "3050 Training Accuracy: 1.0 Validation Accuracy: 0.888206\n",
      "3100 Training Accuracy: 1.0 Validation Accuracy: 0.887797\n",
      "3150 Training Accuracy: 1.0 Validation Accuracy: 0.887797\n",
      "3200 Training Accuracy: 1.0 Validation Accuracy: 0.887387\n",
      "3250 Training Accuracy: 1.0 Validation Accuracy: 0.888206\n",
      "3300 Training Accuracy: 1.0 Validation Accuracy: 0.887387\n",
      "3350 Training Accuracy: 1.0 Validation Accuracy: 0.886978\n",
      "3400 Training Accuracy: 1.0 Validation Accuracy: 0.886568\n"
     ]
    }
   ],
   "source": [
    "#execution phase\n",
    "max_epoch_without_valid_improve = 20 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 50\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    original_saver.restore(sess,'./model1_final.ckpt')\n",
    "    hidden4_outputs = sess.run(hidden4,feed_dict={X:mnist_train_images_5_9})\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        shuffled_idx = np.random.permutation(hidden4_outputs.shape[0])\n",
    "        hidden4_batches = np.array_split(hidden4_outputs[shuffled_idx],batch_size)\n",
    "        y_batches = np.array_split(mnist_train_labels_5_9[shuffled_idx],batch_size)\n",
    "        \n",
    "        for hidden4_batch,y_batch in zip(hidden4_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={hidden4:hidden4_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={hidden4:hidden4_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={X:mnist_valid_images_5_9,y:mnist_valid_labels_5_9})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        new_saver.save(sess,'./model5.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    saver.save(sess,'./model5_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model5_final.ckpt\n",
      "Test Accuracy: 0.882946\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of batch normalization and dropout model on test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model5_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={X:mnist_test_images_5_9,y:mnist_test_labels_5_9})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model5_final.ckpt\n",
      "Prediction: [6 9 7 9 6]\n",
      "Target: [6 9 7 9 6]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data using batch normalization and dropout model\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model5_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={X:mnist_test_images_5_9[2920:2925]}),axis=1) + 5\n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_5_9[2920:2925] + 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a new DNN to classify digits 5 to 9 using first 2 pretained hidden layers of the previous batch normalization model (model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,activation=tf.nn.elu,units=units)\n",
    "    \n",
    "    hidden1 = my_hidden_layer(X,name='hidden1')\n",
    "    hidden2 = my_hidden_layer(hidden1,name='hidden2')\n",
    "    hidden3 = my_hidden_layer(hidden2,name='hidden3')\n",
    "    hidden4 = my_hidden_layer(hidden3,name='hidden4')\n",
    "    hidden5 = my_hidden_layer(hidden4,name='hidden5')\n",
    "    logits = tf.layers.dense(hidden5,n_outputs,name='logits')\n",
    "    \n",
    "    #define variables to save and restore\n",
    "    reuse_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\"hidden[12]\")\n",
    "    reuse_vars_dict = dict([(var.op.name,var) for var in reuse_vars])\n",
    "    #print(reuse_vars_dict)\n",
    "    original_saver = tf.train.Saver(reuse_vars_dict)\n",
    "    \n",
    "    #define variables to train\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='hidden[345]|logits')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op',var_list=train_vars)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model1_final.ckpt\n",
      "50 Training Accuracy: 1.0 Validation Accuracy: 0.837428\n",
      "100 Training Accuracy: 1.0 Validation Accuracy: 0.890254\n",
      "150 Training Accuracy: 1.0 Validation Accuracy: 0.891073\n",
      "200 Training Accuracy: 1.0 Validation Accuracy: 0.904177\n",
      "250 Training Accuracy: 1.0 Validation Accuracy: 0.905405\n",
      "300 Training Accuracy: 1.0 Validation Accuracy: 0.900491\n",
      "350 Training Accuracy: 1.0 Validation Accuracy: 0.90991\n",
      "400 Training Accuracy: 1.0 Validation Accuracy: 0.904996\n",
      "450 Training Accuracy: 1.0 Validation Accuracy: 0.911548\n",
      "500 Training Accuracy: 1.0 Validation Accuracy: 0.913595\n",
      "550 Training Accuracy: 1.0 Validation Accuracy: 0.911957\n",
      "600 Training Accuracy: 1.0 Validation Accuracy: 0.90991\n",
      "650 Training Accuracy: 1.0 Validation Accuracy: 0.911957\n",
      "700 Training Accuracy: 1.0 Validation Accuracy: 0.914824\n",
      "750 Training Accuracy: 1.0 Validation Accuracy: 0.915233\n",
      "800 Training Accuracy: 1.0 Validation Accuracy: 0.914414\n",
      "850 Training Accuracy: 1.0 Validation Accuracy: 0.914824\n",
      "900 Training Accuracy: 1.0 Validation Accuracy: 0.915643\n",
      "950 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "1000 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "1050 Training Accuracy: 1.0 Validation Accuracy: 0.915643\n",
      "1100 Training Accuracy: 1.0 Validation Accuracy: 0.915643\n",
      "1150 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "1200 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "1250 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "1300 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "1350 Training Accuracy: 1.0 Validation Accuracy: 0.915233\n",
      "1400 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "1450 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "1500 Training Accuracy: 1.0 Validation Accuracy: 0.915643\n",
      "1550 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "1600 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "1650 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "1700 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "1750 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "1800 Training Accuracy: 1.0 Validation Accuracy: 0.915643\n",
      "1850 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "1900 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "1950 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2000 Training Accuracy: 1.0 Validation Accuracy: 0.9181\n",
      "2050 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2100 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "2150 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2200 Training Accuracy: 1.0 Validation Accuracy: 0.9181\n",
      "2250 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "2300 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "2350 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2400 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2450 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2500 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2550 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2600 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "2650 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2700 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "2750 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "2800 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "2850 Training Accuracy: 1.0 Validation Accuracy: 0.918509\n",
      "2900 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "2950 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "3000 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "3050 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "3100 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "3150 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "3200 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "3250 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "3300 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "3350 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "3400 Training Accuracy: 1.0 Validation Accuracy: 0.915643\n",
      "3450 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "3500 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "3550 Training Accuracy: 1.0 Validation Accuracy: 0.915643\n",
      "3600 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "3650 Training Accuracy: 1.0 Validation Accuracy: 0.916462\n",
      "3700 Training Accuracy: 1.0 Validation Accuracy: 0.917281\n",
      "3750 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n",
      "3800 Training Accuracy: 1.0 Validation Accuracy: 0.916052\n",
      "3850 Training Accuracy: 1.0 Validation Accuracy: 0.916871\n"
     ]
    }
   ],
   "source": [
    "#execution phase\n",
    "max_epoch_without_valid_improve = 20 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 50\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    original_saver.restore(sess,'./model1_final.ckpt')\n",
    "    hidden2_outputs = sess.run(hidden2,feed_dict={X:mnist_train_images_5_9})\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        shuffled_idx = np.random.permutation(hidden2_outputs.shape[0])\n",
    "        hidden2_batches = np.array_split(hidden2_outputs[shuffled_idx],batch_size)\n",
    "        y_batches = np.array_split(mnist_train_labels_5_9[shuffled_idx],batch_size)\n",
    "        \n",
    "        for hidden2_batch,y_batch in zip(hidden2_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={hidden2:hidden2_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={hidden2:hidden2_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={X:mnist_valid_images_5_9,y:mnist_valid_labels_5_9})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        new_saver.save(sess,'./model6.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    saver.save(sess,'./model6_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model6_final.ckpt\n",
      "Test Accuracy: 0.916684\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of batch normalization and dropout model on test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model6_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={X:mnist_test_images_5_9,y:mnist_test_labels_5_9})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model6_final.ckpt\n",
      "Prediction: [6 9 7 9 6]\n",
      "Target: [6 9 7 9 6]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data using batch normalization and dropout model\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model6_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={X:mnist_test_images_5_9[2920:2925]}),axis=1) + 5\n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_5_9[2920:2925] + 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try introducing **dropoot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "is_training = tf.placeholder(tf.bool,shape=(),name='is_training')\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer12 = partial(tf.layers.dense,kernel_initializer=he_init,activation=tf.nn.elu,units=units)\n",
    "    my_hidden_layer  = partial(tf.layers.dense,kernel_initializer=he_init,units=units)\n",
    "    my_dropout = partial(tf.layers.dropout,rate=0.5,training=is_training)\n",
    "    \n",
    "    hidden1 = my_hidden_layer12(X,name='hidden1')\n",
    "    hidden2 = my_hidden_layer12(hidden1,name='hidden2')\n",
    "    bn2 = my_dropout(hidden2,name='bn2')\n",
    "    hidden3 = my_hidden_layer(bn2,name='hidden3')\n",
    "    bn3 = my_dropout(hidden3,name='bn3')\n",
    "    hidden4 = my_hidden_layer(bn3,name='hidden4')\n",
    "    bn4 = my_dropout(hidden4,name='bn4')\n",
    "    hidden5 = my_hidden_layer(bn4,name='hidden5')\n",
    "    bn5 = my_dropout(hidden5,name='bn5')\n",
    "    logits = tf.layers.dense(bn5,n_outputs,name='logits')\n",
    "    \n",
    "    #define variables to save and restore\n",
    "    reuse_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope=\"hidden[12]\")\n",
    "    reuse_vars_dict = dict([(var.op.name,var) for var in reuse_vars])\n",
    "    #print(reuse_vars_dict)\n",
    "    original_saver = tf.train.Saver(reuse_vars_dict)\n",
    "    \n",
    "    #define variables to train\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='hidden[345]|logits')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op',var_list=train_vars)\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model1_final.ckpt\n",
      "50 Training Accuracy: 0.6 Validation Accuracy: 0.6724\n",
      "100 Training Accuracy: 1.0 Validation Accuracy: 0.751433\n",
      "150 Training Accuracy: 0.6 Validation Accuracy: 0.787469\n",
      "200 Training Accuracy: 0.6 Validation Accuracy: 0.798526\n",
      "250 Training Accuracy: 0.9 Validation Accuracy: 0.799754\n",
      "300 Training Accuracy: 0.8 Validation Accuracy: 0.816953\n",
      "350 Training Accuracy: 0.9 Validation Accuracy: 0.801802\n",
      "400 Training Accuracy: 0.9 Validation Accuracy: 0.823096\n",
      "450 Training Accuracy: 1.0 Validation Accuracy: 0.825962\n",
      "500 Training Accuracy: 0.9 Validation Accuracy: 0.846437\n",
      "550 Training Accuracy: 0.9 Validation Accuracy: 0.835381\n",
      "600 Training Accuracy: 1.0 Validation Accuracy: 0.821867\n",
      "650 Training Accuracy: 0.8 Validation Accuracy: 0.821867\n",
      "700 Training Accuracy: 0.8 Validation Accuracy: 0.823505\n",
      "750 Training Accuracy: 0.9 Validation Accuracy: 0.833333\n",
      "800 Training Accuracy: 0.9 Validation Accuracy: 0.843571\n",
      "850 Training Accuracy: 0.9 Validation Accuracy: 0.84439\n",
      "900 Training Accuracy: 1.0 Validation Accuracy: 0.843161\n",
      "950 Training Accuracy: 1.0 Validation Accuracy: 0.839066\n",
      "1000 Training Accuracy: 1.0 Validation Accuracy: 0.839066\n",
      "1050 Training Accuracy: 0.8 Validation Accuracy: 0.844799\n",
      "1100 Training Accuracy: 0.9 Validation Accuracy: 0.831286\n",
      "1150 Training Accuracy: 0.7 Validation Accuracy: 0.841114\n",
      "1200 Training Accuracy: 0.6 Validation Accuracy: 0.841114\n",
      "1250 Training Accuracy: 0.9 Validation Accuracy: 0.846847\n",
      "1300 Training Accuracy: 0.7 Validation Accuracy: 0.847666\n",
      "1350 Training Accuracy: 0.9 Validation Accuracy: 0.847256\n",
      "1400 Training Accuracy: 1.0 Validation Accuracy: 0.839066\n",
      "1450 Training Accuracy: 0.7 Validation Accuracy: 0.845618\n",
      "1500 Training Accuracy: 1.0 Validation Accuracy: 0.848485\n",
      "1550 Training Accuracy: 0.8 Validation Accuracy: 0.847256\n",
      "1600 Training Accuracy: 0.7 Validation Accuracy: 0.841933\n",
      "1650 Training Accuracy: 0.8 Validation Accuracy: 0.846437\n",
      "1700 Training Accuracy: 0.9 Validation Accuracy: 0.846028\n",
      "1750 Training Accuracy: 0.9 Validation Accuracy: 0.850123\n",
      "1800 Training Accuracy: 1.0 Validation Accuracy: 0.85217\n",
      "1850 Training Accuracy: 0.9 Validation Accuracy: 0.851761\n",
      "1900 Training Accuracy: 1.0 Validation Accuracy: 0.851761\n",
      "1950 Training Accuracy: 0.9 Validation Accuracy: 0.855037\n",
      "2000 Training Accuracy: 0.8 Validation Accuracy: 0.851761\n",
      "2050 Training Accuracy: 0.9 Validation Accuracy: 0.845618\n",
      "2100 Training Accuracy: 1.0 Validation Accuracy: 0.849304\n",
      "2150 Training Accuracy: 1.0 Validation Accuracy: 0.854218\n",
      "2200 Training Accuracy: 1.0 Validation Accuracy: 0.848894\n",
      "2250 Training Accuracy: 0.9 Validation Accuracy: 0.853808\n",
      "2300 Training Accuracy: 1.0 Validation Accuracy: 0.853808\n",
      "2350 Training Accuracy: 1.0 Validation Accuracy: 0.856265\n",
      "2400 Training Accuracy: 0.7 Validation Accuracy: 0.849304\n",
      "2450 Training Accuracy: 1.0 Validation Accuracy: 0.853399\n",
      "2500 Training Accuracy: 0.7 Validation Accuracy: 0.85258\n",
      "2550 Training Accuracy: 0.9 Validation Accuracy: 0.854218\n",
      "2600 Training Accuracy: 0.9 Validation Accuracy: 0.857494\n",
      "2650 Training Accuracy: 0.8 Validation Accuracy: 0.851351\n",
      "2700 Training Accuracy: 0.9 Validation Accuracy: 0.854627\n",
      "2750 Training Accuracy: 0.9 Validation Accuracy: 0.848894\n",
      "2800 Training Accuracy: 0.8 Validation Accuracy: 0.846847\n",
      "2850 Training Accuracy: 0.7 Validation Accuracy: 0.851761\n",
      "2900 Training Accuracy: 1.0 Validation Accuracy: 0.842752\n",
      "2950 Training Accuracy: 0.7 Validation Accuracy: 0.851351\n",
      "3000 Training Accuracy: 0.9 Validation Accuracy: 0.859541\n",
      "3050 Training Accuracy: 1.0 Validation Accuracy: 0.857494\n",
      "3100 Training Accuracy: 1.0 Validation Accuracy: 0.854218\n",
      "3150 Training Accuracy: 0.9 Validation Accuracy: 0.850942\n",
      "3200 Training Accuracy: 0.9 Validation Accuracy: 0.86036\n",
      "3250 Training Accuracy: 0.9 Validation Accuracy: 0.846028\n",
      "3300 Training Accuracy: 1.0 Validation Accuracy: 0.857903\n",
      "3350 Training Accuracy: 0.9 Validation Accuracy: 0.862817\n",
      "3400 Training Accuracy: 0.8 Validation Accuracy: 0.857903\n",
      "3450 Training Accuracy: 0.9 Validation Accuracy: 0.84439\n",
      "3500 Training Accuracy: 1.0 Validation Accuracy: 0.855856\n",
      "3550 Training Accuracy: 1.0 Validation Accuracy: 0.862408\n",
      "3600 Training Accuracy: 1.0 Validation Accuracy: 0.863227\n",
      "3650 Training Accuracy: 1.0 Validation Accuracy: 0.844799\n",
      "3700 Training Accuracy: 0.8 Validation Accuracy: 0.859132\n",
      "3750 Training Accuracy: 0.9 Validation Accuracy: 0.859541\n",
      "3800 Training Accuracy: 0.9 Validation Accuracy: 0.864046\n",
      "3850 Training Accuracy: 0.9 Validation Accuracy: 0.854627\n",
      "3900 Training Accuracy: 1.0 Validation Accuracy: 0.858722\n",
      "3950 Training Accuracy: 0.9 Validation Accuracy: 0.861998\n",
      "4000 Training Accuracy: 0.9 Validation Accuracy: 0.863636\n",
      "4050 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "4100 Training Accuracy: 0.9 Validation Accuracy: 0.862817\n",
      "4150 Training Accuracy: 0.9 Validation Accuracy: 0.86855\n",
      "4200 Training Accuracy: 1.0 Validation Accuracy: 0.873464\n",
      "4250 Training Accuracy: 1.0 Validation Accuracy: 0.871417\n",
      "4300 Training Accuracy: 1.0 Validation Accuracy: 0.857903\n",
      "4350 Training Accuracy: 1.0 Validation Accuracy: 0.862817\n",
      "4400 Training Accuracy: 0.9 Validation Accuracy: 0.86077\n",
      "4450 Training Accuracy: 1.0 Validation Accuracy: 0.862408\n",
      "4500 Training Accuracy: 0.9 Validation Accuracy: 0.864455\n",
      "4550 Training Accuracy: 0.9 Validation Accuracy: 0.866503\n",
      "4600 Training Accuracy: 0.9 Validation Accuracy: 0.868141\n",
      "4650 Training Accuracy: 1.0 Validation Accuracy: 0.861589\n",
      "4700 Training Accuracy: 1.0 Validation Accuracy: 0.871007\n",
      "4750 Training Accuracy: 0.9 Validation Accuracy: 0.86077\n",
      "4800 Training Accuracy: 1.0 Validation Accuracy: 0.856675\n",
      "4850 Training Accuracy: 0.8 Validation Accuracy: 0.852989\n",
      "4900 Training Accuracy: 0.8 Validation Accuracy: 0.86077\n",
      "4950 Training Accuracy: 0.9 Validation Accuracy: 0.863227\n",
      "5000 Training Accuracy: 0.9 Validation Accuracy: 0.864865\n",
      "5050 Training Accuracy: 0.7 Validation Accuracy: 0.861179\n",
      "5100 Training Accuracy: 0.8 Validation Accuracy: 0.863636\n",
      "5150 Training Accuracy: 0.9 Validation Accuracy: 0.873874\n",
      "5200 Training Accuracy: 0.8 Validation Accuracy: 0.862817\n",
      "5250 Training Accuracy: 0.9 Validation Accuracy: 0.853808\n",
      "5300 Training Accuracy: 0.9 Validation Accuracy: 0.858722\n",
      "5350 Training Accuracy: 1.0 Validation Accuracy: 0.856265\n",
      "5400 Training Accuracy: 0.8 Validation Accuracy: 0.856675\n",
      "5450 Training Accuracy: 1.0 Validation Accuracy: 0.866503\n",
      "5500 Training Accuracy: 0.8 Validation Accuracy: 0.864455\n",
      "5550 Training Accuracy: 0.9 Validation Accuracy: 0.859951\n",
      "5600 Training Accuracy: 0.8 Validation Accuracy: 0.863636\n",
      "5650 Training Accuracy: 0.9 Validation Accuracy: 0.868141\n",
      "5700 Training Accuracy: 0.8 Validation Accuracy: 0.867322\n",
      "5750 Training Accuracy: 0.9 Validation Accuracy: 0.870598\n",
      "5800 Training Accuracy: 0.9 Validation Accuracy: 0.869779\n",
      "5850 Training Accuracy: 1.0 Validation Accuracy: 0.86077\n",
      "5900 Training Accuracy: 0.7 Validation Accuracy: 0.869779\n",
      "5950 Training Accuracy: 0.9 Validation Accuracy: 0.862817\n",
      "6000 Training Accuracy: 1.0 Validation Accuracy: 0.854627\n",
      "6050 Training Accuracy: 0.9 Validation Accuracy: 0.863636\n",
      "6100 Training Accuracy: 0.8 Validation Accuracy: 0.859132\n",
      "6150 Training Accuracy: 0.8 Validation Accuracy: 0.871417\n"
     ]
    }
   ],
   "source": [
    "#execution phase\n",
    "max_epoch_without_valid_improve = 20 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 50\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    original_saver.restore(sess,'./model1_final.ckpt')\n",
    "    hidden2_outputs = sess.run(hidden2,feed_dict={X:mnist_train_images_5_9})\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        shuffled_idx = np.random.permutation(hidden2_outputs.shape[0])\n",
    "        hidden2_batches = np.array_split(hidden2_outputs[shuffled_idx],batch_size)\n",
    "        y_batches = np.array_split(mnist_train_labels_5_9[shuffled_idx],batch_size)\n",
    "        \n",
    "        for hidden2_batch,y_batch in zip(hidden2_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={is_training:True,hidden2:hidden2_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={is_training:False,hidden2:hidden2_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={is_training:False,X:mnist_valid_images_5_9,y:mnist_valid_labels_5_9})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        new_saver.save(sess,'./model7.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    saver.save(sess,'./model7_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model7_final.ckpt\n",
      "Test Accuracy: 0.866077\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy of batch normalization and dropout model on test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model7_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={is_training:False,X:mnist_test_images_5_9,y:mnist_test_labels_5_9})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model7_final.ckpt\n",
      "Prediction: [6 9 7 9 6]\n",
      "Target: [6 9 7 9 6]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data using batch normalization and dropout model\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model7_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={is_training:False,X:mnist_test_images_5_9[2920:2925]}),axis=1) + 5\n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_5_9[2920:2925] + 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Try training DNN to classify 5 to 9 **from scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a new DNN to classify digits 5 to 9 from scratch\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,activation=tf.nn.elu,units=units)\n",
    "    \n",
    "    hidden1 = my_hidden_layer(X,name='hidden1')\n",
    "    hidden2 = my_hidden_layer(hidden1,name='hidden2')\n",
    "    hidden3 = my_hidden_layer(hidden2,name='hidden3')\n",
    "    hidden4 = my_hidden_layer(hidden3,name='hidden4')\n",
    "    hidden5 = my_hidden_layer(hidden4,name='hidden5')\n",
    "    logits = tf.layers.dense(hidden5,n_outputs,name='logits')\n",
    "    \n",
    "    \n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op')\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Training Accuracy: 0.8 Validation Accuracy: 0.890254\n",
      "100 Training Accuracy: 0.9 Validation Accuracy: 0.879607\n",
      "150 Training Accuracy: 0.9 Validation Accuracy: 0.912776\n",
      "200 Training Accuracy: 1.0 Validation Accuracy: 0.913595\n",
      "250 Training Accuracy: 1.0 Validation Accuracy: 0.91769\n",
      "300 Training Accuracy: 1.0 Validation Accuracy: 0.922195\n",
      "350 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "400 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "450 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "500 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "550 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "600 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "650 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "700 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "750 Training Accuracy: 1.0 Validation Accuracy: 0.925471\n",
      "800 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "850 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "900 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "950 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1000 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1050 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1100 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1150 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1200 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "1250 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "1300 Training Accuracy: 1.0 Validation Accuracy: 0.927109\n",
      "1350 Training Accuracy: 1.0 Validation Accuracy: 0.927518\n",
      "1400 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "1450 Training Accuracy: 1.0 Validation Accuracy: 0.927109\n",
      "1500 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "1550 Training Accuracy: 1.0 Validation Accuracy: 0.927109\n",
      "1600 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "1650 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1700 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1750 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1800 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1850 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1900 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "1950 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "2000 Training Accuracy: 1.0 Validation Accuracy: 0.926699\n",
      "2050 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "2100 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "2150 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "2200 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "2250 Training Accuracy: 1.0 Validation Accuracy: 0.92629\n",
      "2300 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n",
      "2350 Training Accuracy: 1.0 Validation Accuracy: 0.92588\n"
     ]
    }
   ],
   "source": [
    "#execution phase\n",
    "max_epoch_without_valid_improve = 20 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 50\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        shuffled_idx = np.random.permutation(mnist_train_images_5_9.shape[0])\n",
    "        x_batches = np.array_split(mnist_train_images_5_9[shuffled_idx],batch_size)\n",
    "        y_batches = np.array_split(mnist_train_labels_5_9[shuffled_idx],batch_size)\n",
    "        \n",
    "        for x_batch,y_batch in zip(x_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={X:x_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={X:x_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={X:mnist_valid_images_5_9,y:mnist_valid_labels_5_9})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        new_saver.save(sess,'./model8.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    saver.save(sess,'./model8_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model8_final.ckpt\n",
      "Test Accuracy: 0.922444\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model8_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={X:mnist_test_images_5_9,y:mnist_test_labels_5_9})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model8_final.ckpt\n",
      "Prediction: [6 9 7 9 6]\n",
      "Target: [6 9 7 9 6]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model8_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={X:mnist_test_images_5_9[2920:2925]}),axis=1) + 5\n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_5_9[2920:2925] + 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ## Classifying digits 5 to 9 with the whole MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess data for training. Using digits 5 to 9\n",
    "# shift labels such that  5->0,6->1,7->2,8->3,9->4\n",
    "import numpy as np\n",
    "\n",
    "#training set\n",
    "train_index_5_9 = np.random.permutation(np.nonzero(mnist.train.labels >= 5)[0]) \n",
    "mnist_train_images_5_9 = mnist.train.images[train_index_5_9]\n",
    "mnist_train_labels_5_9 = mnist.train.labels[train_index_5_9] - 5\n",
    "\n",
    "#validation set\n",
    "valid_index_5_9 = np.random.permutation(np.nonzero(mnist.validation.labels >= 5)[0]) \n",
    "mnist_valid_images_5_9 = mnist.validation.images[valid_index_5_9]\n",
    "mnist_valid_labels_5_9 = mnist.validation.labels[valid_index_5_9] - 5\n",
    "\n",
    "#test set\n",
    "test_index_5_9 = np.random.permutation(np.nonzero(mnist.test.labels >= 5)[0]) \n",
    "mnist_test_images_5_9 = mnist.test.images[test_index_5_9]\n",
    "mnist_test_labels_5_9 = mnist.test.labels[test_index_5_9] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a new DNN to classify digits 5 to 9 from scratch\n",
    "from functools import partial\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "units = 100\n",
    "n_outputs = 5\n",
    "n_inputs = 28 * 28 #MNIST\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y = tf.placeholder(tf.int64,shape=(None),name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "    my_hidden_layer = partial(tf.layers.dense,kernel_initializer=he_init,activation=tf.nn.elu,units=units)\n",
    "    \n",
    "    hidden1 = my_hidden_layer(X,name='hidden1')\n",
    "    hidden2 = my_hidden_layer(hidden1,name='hidden2')\n",
    "    hidden3 = my_hidden_layer(hidden2,name='hidden3')\n",
    "    hidden4 = my_hidden_layer(hidden3,name='hidden4')\n",
    "    hidden5 = my_hidden_layer(hidden4,name='hidden5')\n",
    "    logits = tf.layers.dense(hidden5,n_outputs,name='logits')\n",
    "    \n",
    "    \n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "    loss = tf.reduce_mean(xentropy,name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001)\n",
    "    training_op = optimizer.minimize(loss,name='training_op')\n",
    "    \n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32),name='eval')\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()\n",
    "valid_accuracy = tf.placeholder(tf.float32,shape=())\n",
    "valid_summary = tf.summary.scalar('valid_accuracy',valid_accuracy)\n",
    "summary_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Training Accuracy: 0.974026 Validation Accuracy: 0.958231\n",
      "100 Training Accuracy: 0.975881 Validation Accuracy: 0.96683\n",
      "150 Training Accuracy: 0.979592 Validation Accuracy: 0.969697\n",
      "200 Training Accuracy: 0.972171 Validation Accuracy: 0.973792\n",
      "250 Training Accuracy: 0.987013 Validation Accuracy: 0.973792\n",
      "300 Training Accuracy: 0.988868 Validation Accuracy: 0.977068\n",
      "350 Training Accuracy: 0.994434 Validation Accuracy: 0.978296\n",
      "400 Training Accuracy: 0.992579 Validation Accuracy: 0.976249\n",
      "450 Training Accuracy: 0.994434 Validation Accuracy: 0.982801\n",
      "500 Training Accuracy: 0.998145 Validation Accuracy: 0.979934\n",
      "550 Training Accuracy: 0.996289 Validation Accuracy: 0.983211\n",
      "600 Training Accuracy: 0.998145 Validation Accuracy: 0.982801\n",
      "650 Training Accuracy: 0.998145 Validation Accuracy: 0.984029\n",
      "700 Training Accuracy: 0.998145 Validation Accuracy: 0.98362\n",
      "750 Training Accuracy: 1.0 Validation Accuracy: 0.982801\n",
      "800 Training Accuracy: 1.0 Validation Accuracy: 0.981163\n",
      "850 Training Accuracy: 0.998145 Validation Accuracy: 0.984439\n",
      "900 Training Accuracy: 1.0 Validation Accuracy: 0.984439\n",
      "950 Training Accuracy: 1.0 Validation Accuracy: 0.984848\n",
      "1000 Training Accuracy: 1.0 Validation Accuracy: 0.984848\n",
      "1050 Training Accuracy: 1.0 Validation Accuracy: 0.984439\n",
      "1100 Training Accuracy: 1.0 Validation Accuracy: 0.985667\n",
      "1150 Training Accuracy: 1.0 Validation Accuracy: 0.983211\n",
      "1200 Training Accuracy: 1.0 Validation Accuracy: 0.984439\n",
      "1250 Training Accuracy: 1.0 Validation Accuracy: 0.984848\n",
      "1300 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "1350 Training Accuracy: 1.0 Validation Accuracy: 0.985667\n",
      "1400 Training Accuracy: 1.0 Validation Accuracy: 0.986077\n",
      "1450 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "1500 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "1550 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "1600 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "1650 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "1700 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "1750 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "1800 Training Accuracy: 1.0 Validation Accuracy: 0.986077\n",
      "1850 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "1900 Training Accuracy: 1.0 Validation Accuracy: 0.986077\n",
      "1950 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "2000 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "2050 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "2100 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "2150 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "2200 Training Accuracy: 1.0 Validation Accuracy: 0.987305\n",
      "2250 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2300 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "2350 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n",
      "2400 Training Accuracy: 1.0 Validation Accuracy: 0.987305\n",
      "2450 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2500 Training Accuracy: 1.0 Validation Accuracy: 0.987305\n",
      "2550 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2600 Training Accuracy: 1.0 Validation Accuracy: 0.987305\n",
      "2650 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2700 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2750 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2800 Training Accuracy: 1.0 Validation Accuracy: 0.987305\n",
      "2850 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2900 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "2950 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "3000 Training Accuracy: 1.0 Validation Accuracy: 0.987305\n",
      "3050 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "3100 Training Accuracy: 1.0 Validation Accuracy: 0.986896\n",
      "3150 Training Accuracy: 1.0 Validation Accuracy: 0.987305\n",
      "3200 Training Accuracy: 1.0 Validation Accuracy: 0.986486\n"
     ]
    }
   ],
   "source": [
    "#execution phase\n",
    "max_epoch_without_valid_improve = 20 # stop training if validation accuracy does not improve in five successive epochs\n",
    "batch_size = 50\n",
    "global_step_count = 0\n",
    "epoch_count = 0\n",
    "best_accu_valid = 0\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    while epoch_count < max_epoch_without_valid_improve:\n",
    "        shuffled_idx = np.random.permutation(mnist_train_images_5_9.shape[0])\n",
    "        x_batches = np.array_split(mnist_train_images_5_9[shuffled_idx],batch_size)\n",
    "        y_batches = np.array_split(mnist_train_labels_5_9[shuffled_idx],batch_size)\n",
    "        \n",
    "        for x_batch,y_batch in zip(x_batches,y_batches):\n",
    "            sess.run(training_op,feed_dict={X:x_batch,y:y_batch})\n",
    "            global_step_count += 1\n",
    "        accu_train = accuracy.eval(feed_dict={X:x_batch,y:y_batch})\n",
    "        accu_valid = accuracy.eval(feed_dict={X:mnist_valid_images_5_9,y:mnist_valid_labels_5_9})  \n",
    "        if accu_valid > best_accu_valid:\n",
    "            best_accu_valid = accu_valid\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "        summary_str = valid_summary.eval(feed_dict={valid_accuracy:accu_valid})\n",
    "        summary_writer.add_summary(summary_str, global_step_count)\n",
    "        new_saver.save(sess,'./model9.ckpt')\n",
    "        print(global_step_count,'Training Accuracy:',accu_train,'Validation Accuracy:',accu_valid)\n",
    "    \n",
    "    new_saver.save(sess,'./model9_final.ckpt')\n",
    "        \n",
    "\n",
    "summary_writer.flush()\n",
    "summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model9_final.ckpt\n",
      "Test Accuracy: 0.98416\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy \n",
    "with tf.Session() as sess:\n",
    "    new_saver.restore(sess,'./model9_final.ckpt')\n",
    "    accu_test = accuracy.eval(feed_dict={X:mnist_test_images_5_9,y:mnist_test_labels_5_9})  \n",
    "    print('Test Accuracy:',accu_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model9_final.ckpt\n",
      "Prediction: [8 5 6 9 9]\n",
      "Target: [8 5 6 9 9]\n"
     ]
    }
   ],
   "source": [
    "# do some predictions on the test data\n",
    "with tf.Session() as sess:\n",
    "    new_saver.restore(sess,'./model9_final.ckpt')\n",
    "    label_pred = np.argmax(sess.run(logits,feed_dict={X:mnist_test_images_5_9[3873:3878]}),axis=1) + 5\n",
    "    \n",
    "print('Prediction:',label_pred)\n",
    "print('Target:',mnist_test_labels_5_9[3873:3878] + 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPz1QJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf6195c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show images corresponding to predicted digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.subplot(151)\n",
    "plt.imshow(mnist_test_images_5_9[3873].reshape(28,28))\n",
    "plt.subplot(152)\n",
    "plt.imshow(mnist_test_images_5_9[3874].reshape(28,28))\n",
    "plt.subplot(153)\n",
    "plt.imshow(mnist_test_images_5_9[3875].reshape(28,28))\n",
    "plt.subplot(154)\n",
    "plt.imshow(mnist_test_images_5_9[3876].reshape(28,28))\n",
    "plt.subplot(155)\n",
    "plt.imshow(mnist_test_images_5_9[3877].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_tensaflo",
   "language": "python",
   "name": "tensaflo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
